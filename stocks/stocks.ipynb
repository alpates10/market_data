{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a1151d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import mplfinance as mpf\n",
    "import os\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import glob\n",
    "import re\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0059e67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Fetch detailed company information from Yahoo Finance for each ticker file.\n",
    "Parameters:\n",
    "    tickers_dir: Directory containing CSV files with ticker symbols.\n",
    "    output_dir: Directory where the stock info CSVs will be saved.\n",
    "    limit: \n",
    "        - If int, only that many tickers will be processed.\n",
    "        - If 'all' or a number larger than total, all tickers will be processed.\n",
    "\"\"\"\n",
    "def fetch_stock_info(tickers_dir=\"tickers\", output_dir=\"stocks_info\", limit=\"all\"):\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for file in os.listdir(tickers_dir):\n",
    "        if not file.endswith(\".csv\"):\n",
    "            continue\n",
    "        \n",
    "        input_path = os.path.join(tickers_dir, file)\n",
    "        output_path = os.path.join(output_dir, file.replace(\"_tickers\", \"_info\"))\n",
    "\n",
    "        df = pd.read_csv(input_path)\n",
    "        symbols = df[\"Symbol\"].dropna().unique().tolist()\n",
    "\n",
    "        # Apply limit\n",
    "        if isinstance(limit, int) and limit < len(symbols):\n",
    "            symbols = symbols[:limit]\n",
    "            print(f\"Processing first {limit} tickers from {file}.\")\n",
    "        else:\n",
    "            print(f\"Processing all {len(symbols)} tickers from {file}.\")\n",
    "\n",
    "        print(f\"\\nFetching data for {len(symbols)} symbols...\")\n",
    "\n",
    "        info_list = []\n",
    "\n",
    "        for sym in tqdm(symbols, desc=f\"{file}\"):\n",
    "            try:\n",
    "                ticker = yf.Ticker(sym)\n",
    "                info = ticker.info\n",
    "                if info:\n",
    "                    info_list.append(info)\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Could not retrieve data for {sym}: {e}\")\n",
    "\n",
    "        if info_list:\n",
    "            info_df = pd.DataFrame(info_list)\n",
    "            info_df.to_csv(output_path, index=False, encoding=\"utf-8-sig\")\n",
    "            print(f\"Saved {len(info_df)} records to {output_path}\")\n",
    "        else:\n",
    "            print(f\"No data retrieved for {file}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847d05ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_stock_info(\"tickers\", \"stocks_info\", limit=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667aeed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in pd.read_csv(\"stocks_info/bist100_info.csv\").columns: print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd7da52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_index_prices(index_name, csv_path, limit=\"all\", start_date=\"auto\", end_date=\"auto\"):\n",
    "    # Output directory\n",
    "    data_dir = f\"stocks_price_data/{index_name}_stocks\"\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "    \n",
    "    # Date Control\n",
    "    if start_date == \"auto\":\n",
    "        start_date = \"1900-01-01\"\n",
    "    if end_date == \"auto\":\n",
    "        end_date = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    # Read tickers\n",
    "    df = pd.read_csv(csv_path)\n",
    "    if \"Symbol\" not in df.columns:\n",
    "        print(f\"No 'Symbol' column found in {csv_path}\")\n",
    "        return\n",
    "\n",
    "    symbols = df[\"Symbol\"].astype(str).str.strip().tolist()\n",
    "    \n",
    "    # Limit Control\n",
    "    total = len(symbols)\n",
    "    if isinstance(limit, int) and limit > 0 and limit < total:\n",
    "        print(f\"Processing first {limit} tickers from {index_name.upper()} (total {total}).\")\n",
    "        symbols = symbols[:limit]\n",
    "    else:\n",
    "        print(f\"Processing all {total} tickers from {index_name.upper()}.\")\n",
    "    \n",
    "    print(f\"\\nDownloading {len(symbols)} tickers from {index_name.upper()}...\")\n",
    "\n",
    "    for symbol in symbols:\n",
    "        try:\n",
    "            df_data = yf.download(symbol, start=start_date, end=end_date)\n",
    "            if not df_data.empty:\n",
    "                file_path = os.path.join(data_dir, f\"{symbol}.csv\")\n",
    "                df_data.to_csv(file_path)\n",
    "                print(f\"{symbol}: {len(df_data)} rows saved.\")\n",
    "            else:\n",
    "                print(f\"{symbol}: no data found.\")\n",
    "        except Exception as e:\n",
    "            print(f\"{symbol} error: {e}\")\n",
    "\n",
    "    print(f\"All data saved to '{data_dir}/'\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e77aaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_files = {\n",
    "    \"sp500\":      \"tickers/sp500_tickers.csv\",\n",
    "    \"dowjones\":   \"tickers/dowjones_tickers.csv\",\n",
    "    \"nasdaq100\":  \"tickers/nasdaq100_tickers.csv\",\n",
    "    \"nifty50\":    \"tickers/nifty50_tickers.csv\",\n",
    "    \"bist100\":    \"tickers/bist100_tickers.csv\",\n",
    "    \"sse\":        \"tickers/sse_tickers.csv\",\n",
    "}\n",
    "\n",
    "for name, path in index_files.items():\n",
    "    if os.path.exists(path):\n",
    "        download_index_prices(name, path, limit=\"all\")\n",
    "    else:\n",
    "        print(f\"Skipping {name}, file not found: {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6edb06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(\"stocks_price_data/sp500_stocks\", \"AAPL.csv\"))\n",
    "print(df.head())\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b965771",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Clean all downloaded stock CSVs inside subfolders (sp500_stocks, dowjones_stocks, etc.)\n",
    "    Removes header issues and converts columns to standard format.\n",
    "\"\"\"\n",
    "    \n",
    "def clean_all_stock_data(base_dir=\"stocks_price_data\"):\n",
    "    # Get all subfolders\n",
    "    subfolders = [f.path for f in os.scandir(base_dir) if f.is_dir()]\n",
    "\n",
    "    for folder in subfolders:\n",
    "        csv_files = glob.glob(os.path.join(folder, \"*.csv\"))\n",
    "        print(f\"\\n=== Cleaning {len(csv_files)} files in {os.path.basename(folder)} ===\")\n",
    "\n",
    "        for file in csv_files:\n",
    "            symbol = os.path.basename(file).replace(\".csv\", \"\")\n",
    "\n",
    "            try:\n",
    "                df_raw = pd.read_csv(file)\n",
    "\n",
    "                # If file is too short or incomplete, skip\n",
    "                if len(df_raw) < 3:\n",
    "                    print(f\"{symbol}: not enough data, skipped.\")\n",
    "                    continue\n",
    "\n",
    "                # Drop the first two rows\n",
    "                df_clean = df_raw.drop([0, 1])\n",
    "\n",
    "                # Fix column names\n",
    "                df_clean.columns = [\"Date\", \"Close\", \"High\", \"Low\", \"Open\", \"Volume\"]\n",
    "\n",
    "                # Convert date to datetime\n",
    "                df_clean[\"Date\"] = pd.to_datetime(df_clean[\"Date\"], errors=\"coerce\")\n",
    "\n",
    "                # Convert numeric columns to float\n",
    "                for col in [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]:\n",
    "                    df_clean[col] = pd.to_numeric(df_clean[col], errors=\"coerce\")\n",
    "\n",
    "                # Reset index\n",
    "                df_clean.reset_index(drop=True, inplace=True)\n",
    "\n",
    "                # Overwrite the original file\n",
    "                df_clean.to_csv(file, index=False)\n",
    "\n",
    "                print(f\"{symbol}: {len(df_clean)} rows cleaned and saved.\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"{symbol}: error â†’ {e}\")\n",
    "\n",
    "    print(\"\\nAll files cleaned successfully!\")\n",
    "\n",
    "clean_all_stock_data(\"stocks_price_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acb0e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(\"stocks_price_data/sp500_stocks\", \"AAPL.csv\"))\n",
    "print(df.head())\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45758948",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stock(file_path, symbol, period_days=180):\n",
    "    # Read CSV\n",
    "    df = pd.read_csv(f\"{file_path}/{symbol}.csv\", parse_dates=[\"Date\"])\n",
    "    df.set_index(\"Date\", inplace=True)\n",
    "\n",
    "    # Get last period_days data\n",
    "    df_tail = df.tail(period_days)\n",
    "\n",
    "    # Create plot\n",
    "    mpf.plot(\n",
    "        df_tail,\n",
    "        type=\"candle\",\n",
    "        title=f\"{symbol.upper()} (Last {period_days} Days)\",\n",
    "        ylabel=\"Price (USD)\",\n",
    "        style=\"yahoo\",\n",
    "        datetime_format=\"%Y-%m-%d\",\n",
    "        xrotation=15,\n",
    "        figratio=(16, 9),\n",
    "        figscale=1.3,\n",
    "        tight_layout=True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eecc3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example \n",
    "plot_stock(\"stocks_price_data/sp500_stocks/\", \"AAPL\", 180)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
